{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 08:18:10.040437: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746598690.108863   11227 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746598690.126251   11227 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746598690.254926   11227 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746598690.254961   11227 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746598690.254964   11227 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746598690.254966   11227 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-07 08:18:10.268389: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.typing as npt\n",
    "\n",
    "\n",
    "def preprocess_images(images: npt.NDArray[np.float32]) -> npt.NDArray[np.float32]:\n",
    "    \"\"\"Reshape and normalize images.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    images : npt.NDArray[np.float32]\n",
    "        Images to be preprocessed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    npt.NDArray[np.float32]\n",
    "        Preprocessed images.\n",
    "    \"\"\"\n",
    "\n",
    "    images = images.reshape(shape=(images.shape[0], 28, 28, 1)) / 255.0\n",
    "    return np.where(images > 0.5, 1.0, 0.0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746598693.470790   11227 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3414 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "ds_train = (\n",
    "    tf.data.Dataset.from_tensor_slices(tensors=x_train)\n",
    "    .shuffle(buffer_size=len(x_train))\n",
    "    .batch(batch_size=batch_size)\n",
    ")\n",
    "ds_test = (\n",
    "    tf.data.Dataset.from_tensor_slices(tensors=x_test)\n",
    "    .shuffle(buffer_size=len(x_test))\n",
    "    .batch(batch_size=batch_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Define Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(tf.keras.Model):\n",
    "    \"\"\"Conditional Variational Autoencoder (CVAE) class.\"\"\"\n",
    "\n",
    "    def __init__(self, latent_dim: int) -> None:\n",
    "        \"\"\"Instantiate the CVAE\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        latent_dim : int\n",
    "            Size of the latent space.\n",
    "        \"\"\"\n",
    "        super(CVAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=32,\n",
    "                    kernel_size=3,\n",
    "                    strides=(2, 2),\n",
    "                    activation=tf.nn.relu,\n",
    "                ),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=64,\n",
    "                    kernel_size=3,\n",
    "                    strides=(2, 2),\n",
    "                    activation=tf.nn.relu,\n",
    "                ),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(units=latent_dim + latent_dim),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.decoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "                tf.keras.layers.Dense(units=7 * 7 * 32, activation=tf.nn.relu),\n",
    "                tf.keras.layers.Reshape(target_shape=(7, 7, 32)),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=64,\n",
    "                    kernel_size=3,\n",
    "                    strides=2,\n",
    "                    padding=\"same\",\n",
    "                    activation=tf.nn.relu,\n",
    "                ),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=32,\n",
    "                    kernel_size=3,\n",
    "                    strides=2,\n",
    "                    padding=\"same\",\n",
    "                    activation=tf.nn.relu,\n",
    "                ),\n",
    "                tf.keras.layers.Conv2DTranspose(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    @tf.function\n",
    "    def sample(self, eps: tf.Tensor = None) -> tf.Tensor:\n",
    "        \"\"\"Sample with the decoder.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        eps : tf.Tensor, optional\n",
    "            Independently samples from standard normal distribution. If None, generate 100 samples.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tf.Tensor\n",
    "            Generated sample images.\n",
    "        \"\"\"\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=True)\n",
    "    \n",
    "    def encode(self, x: tf.Tensor) -> tuple[tf.Tensor, tf.Tensor]:\n",
    "        \"\"\"Encode the input images into a latent space.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : tf.Tensor\n",
    "            Input images.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple[tf.Tensor, tf.Tensor]\n",
    "            Mean and log variance of the images in the latent space.\n",
    "        \"\"\"\n",
    "        mean, logvar = tf.split(value=self.encoder(x=x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "    \n",
    "    def reparameterize(self, mean: tf.Tensor, logvar: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"Reparameterization \n",
    "        \n",
    "        Get the input for the decoder.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mean : tf.Tensor\n",
    "            Mean values of the input images in the latent space.\n",
    "        logvar : tf.Tensor\n",
    "            Log variance of the input images in the latent space.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tf.Tensor\n",
    "            Input for the decoder.\n",
    "        \"\"\"\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * 0.5) + mean\n",
    "    \n",
    "    def decode(self, z: tf.Tensor, apply_sigmoid: bool = False):\n",
    "        \"\"\"Generate images from the latent space.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        z : tf.Tensor\n",
    "            Reparameterized embeddings of the images from latent space.\n",
    "        apply_sigmoid : bool, optional\n",
    "            If to apply sigmoid before output, by default False\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tf.Tensor\n",
    "            Generated images with the value for each pixel as logits or probabilities.\n",
    "        \"\"\"\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Define Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "\n",
    "def log_normal_pdf(sample: tf.Tensor, mean: tf.Tensor, logvar: tf.Tensor, raxis: int=1):\n",
    "    log2pi = tf.math.log(2.0 * np.pi)\n",
    "    return tf.reduce_sum(\n",
    "        input_tensor=-0.5\n",
    "        * ((sample - mean) ** 2.0 * tf.exp(-logvar) + logvar + log2pi),\n",
    "        axis=raxis,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
